# Auto-Parallelization Multi-Agent System üöÄ

An intelligent agentic system that automatically optimizes code by identifying slow sequential loops and refactoring them into parallel implementations.

**Supported Languages:**
- üêç **Python** ‚Üí Parallelized using `joblib`
- ‚ö° **C** ‚Üí Parallelized using `OpenMP`

## üèóÔ∏è Architecture

The system uses **LangGraph** to coordinate specialized AI agents with language-specific workflows and a consistent feedback loop.

```mermaid
graph TD
    User[User Input File] --> Main[main.py]
    Main -->|Detect Language| Router{.py or .c?}
    
    Router -->|Python| PyWorkflow[Python Workflow]
    Router -->|C| CWorkflow[C Workflow]
    
    subgraph "Python Workflow (joblib)"
        PyAST["AST Parser"] --> PyAnalyzer[Analyzer Agent]
        PyAnalyzer --> PyImpl[Implementer Agent]
        PyImpl --> PyVal[Validator Agent]
        PyVal -->|Run Python| PyCheck{Valid?}
        PyCheck -->|No| PyImpl
        PyCheck -->|Yes| PyOut[Save _optimized.py]
    end
    
    subgraph "C Workflow (OpenMP)"
        CAST["C AST Parser"] --> CAnalyzer[C Analyzer Agent]
        CAnalyzer --> CImpl[C Implementer Agent]
        CImpl --> CVal[C Validator Agent]
        CVal -->|Compile & Run| CCheck{Valid?}
        CCheck -->|No| CImpl
        CCheck -->|Yes| COut[Save _parallel.c]
    end
```

## ‚ú® Features

### Common Features
-   **Static Analysis (AST)**: Mathematically precise identification of loops and variables before the AI sees the code.
-   **Multi-Agent Workflow**: Analyzer ‚Üí Implementer ‚Üí Validator pipeline with retry loops.
-   **Safe Execution**: Runs validation in temporary sandboxes that are automatically cleaned up.
-   **No Hallucinations**: Code is strictly validated by execution, not just by "looking valid".

### Python-Specific
-   üïµÔ∏è **Analyzer**: Uses Python `ast` module + LLM reasoning to find parallelizable loops.
-   üë∑ **Implementer**: Refactors using `joblib.Parallel` and `delayed`.
-   ‚úÖ **Validator**: Generates Python test scripts to verify output correctness and speedup.

### C-Specific (OpenMP)
-   üïµÔ∏è **Analyzer**: Uses `pycparser` for C AST analysis, detects data dependencies, reduction patterns.
-   üë∑ **Implementer**: Adds `#pragma omp parallel for` with appropriate clauses:
    - `reduction()` for accumulation patterns
    - `private()` / `shared()` for variable scoping
    - `schedule()` for load balancing
-   ‚úÖ **Validator**: Compiles with `gcc -fopenmp`, runs both versions, compares outputs.

## üöÄ Getting Started

### Prerequisites

-   Python 3.10+
-   Azure OpenAI API Key (or compatible LLM config)
-   **For C support**: GCC with OpenMP support (`gcc -fopenmp`)

### Installation

1.  Clone the repository.
2.  Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
3.  Configure your environment variables in `.env`:
    ```ini
    GPT_OSS_DEPLOYMENT_NAME=gpt-4o
    AZURE_OPENAI_API_VERSION=...
    AZURE_OPENAI_ENDPOINT=...
    AZURE_OPENAI_API_KEY=...
    ```

4.  **(For C support)** Ensure GCC with OpenMP is installed:
    ```bash
    # Ubuntu/Debian
    sudo apt install gcc
    
    # macOS (with Homebrew)
    brew install gcc
    
    # Windows (MinGW-w64 or WSL recommended)
    # Download from: https://winlibs.com/
    ```

## üíª Usage

### Python Files

```bash
# Auto-detect language from extension
python main.py path/to/your_script.py

# Specify custom output
python main.py script.py -o optimized_script.py
```

### C Files

```bash
# Auto-detect language from extension
python main.py path/to/program.c

# Specify custom output
python main.py program.c -o program_omp.c

# Force language (for non-standard extensions)
python main.py code.txt --language c
```

### CLI Options

```
usage: main.py [-h] [--output OUTPUT] [--language {python,c}] input_file

positional arguments:
  input_file            Path to the source file (.py for Python, .c for C)

optional arguments:
  -h, --help            Show this help message and exit
  --output, -o OUTPUT   Path to save the optimized code
  --language, -l {python,c}
                        Force language (auto-detected from extension if not specified)
```

## üìù Examples

### Python Example

**Input (`workload.py`)**:
```python
def main():
    results = []
    for i in range(10):
        results.append(slow_function(i))
```

**Output (`workload_optimized.py`)**:
```python
from joblib import Parallel, delayed

def main():
    results = Parallel(n_jobs=-1)(delayed(slow_function)(i) for i in range(10))
```

### C Example

**Input (`sum_array.c`)**:
```c
#include <stdio.h>

int main() {
    int arr[1000];
    int sum = 0;
    
    for (int i = 0; i < 1000; i++) {
        arr[i] = i;
    }
    
    for (int i = 0; i < 1000; i++) {
        sum += arr[i];
    }
    
    printf("Sum: %d\n", sum);
    return 0;
}
```

**Output (`sum_array_parallel.c`)**:
```c
#include <stdio.h>
#include <omp.h>

int main() {
    int arr[1000];
    int sum = 0;
    
    #pragma omp parallel for
    for (int i = 0; i < 1000; i++) {
        arr[i] = i;
    }
    
    #pragma omp parallel for reduction(+:sum)
    for (int i = 0; i < 1000; i++) {
        sum += arr[i];
    }
    
    printf("Sum: %d\n", sum);
    return 0;
}
```

**Compile and run**:
```bash
gcc -fopenmp -o sum_parallel sum_array_parallel.c
./sum_parallel
```

## üìÇ Project Structure

```
MAAP/
‚îú‚îÄ‚îÄ main.py                 # CLI entry point with language detection
‚îú‚îÄ‚îÄ graphs/
‚îÇ   ‚îî‚îÄ‚îÄ workflow.py         # LangGraph state machine with dual workflows
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ analyser.py         # Python loop analyzer
‚îÇ   ‚îú‚îÄ‚îÄ implementer.py      # Python joblib implementer
‚îÇ   ‚îú‚îÄ‚îÄ validator.py        # Python validation script generator
‚îÇ   ‚îú‚îÄ‚îÄ ast_utils.py        # Python AST walker utility
‚îÇ   ‚îú‚îÄ‚îÄ c_analyser.py       # C loop analyzer (OpenMP-focused)
‚îÇ   ‚îú‚îÄ‚îÄ c_implementer.py    # C OpenMP pragma implementer
‚îÇ   ‚îú‚îÄ‚îÄ c_validator.py      # C compilation & validation generator
‚îÇ   ‚îî‚îÄ‚îÄ c_ast_utils.py      # C AST parser using pycparser
‚îú‚îÄ‚îÄ LLMs/
‚îÇ   ‚îî‚îÄ‚îÄ azure_models.py     # LLM configuration
‚îú‚îÄ‚îÄ temp_env/               # (Ephemeral) Python validation sandbox
‚îú‚îÄ‚îÄ temp_env_c/             # (Ephemeral) C compilation sandbox
‚îî‚îÄ‚îÄ requirements.txt
```

## üîß Requirements

| Dependency | Purpose |
|------------|---------|
| `langchain` | LLM chain orchestration |
| `langgraph` | Stateful agent workflow graphs |
| `pycparser` | C code AST parsing |
| `joblib` | Python parallel execution |
| `python-dotenv` | Environment variable loading |

## ‚ö†Ô∏è Limitations

- **C Preprocessing**: `pycparser` requires preprocessed C code. Complex `#include` chains may need manual preprocessing with `gcc -E`.
- **OpenMP Support**: The target system must have GCC/Clang with OpenMP support installed.
- **Data Dependencies**: The AI attempts to detect dependencies, but complex pointer aliasing in C may be missed.

## üìÑ License

MIT License - See LICENSE file for details.
